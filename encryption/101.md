---
type: article
status: draft
---

# How to talk in 1s and 0s?

You've probably heard a few times that computers talk in 1s and 0s. But we know they "talk" about a lot of things, right? How do they exchange text for example? I understand they convert text into 1s and 0s, but how? That's the question I recently find myself answering.

I did describe the process on a high level, and the person asking even looked satisfied with my answer. However, I felt that my explanation was vague and had a few blind spots. So I decided to study the topic myself and give it another try, this time in writing. In this attempt besides a clear general explanation of the concept, I aim to explain __exactly__ how it plays out in real life.

> Besides that I'll try to give you an explanation for the words you may face when studying this or a related topic. The words we'll need right away are **bits** and **binary**. A bit is a thing that can hold exactly two states - 0 or 1 for example. So we might, as well, say that computers talk in bits. And since a bit sequence is a sequence of things that can be one of two the sequence is called binary sequence, or simply **binary**.

## Creating an encoding

Perhaps, the best way to understand something is to build it. That's exactly what we are going to do. We'll create a system to convert the string into a binary sequence a.k.a. **encode** the string, and then receiving the binary sequence convert it back to the string a.k.a **decode** the binary sequence. Unoriginally, the types of "systems" are called **encoding**.

For simplicity's sake let's limit our alphabet to 8 symbols.s

| Char | Code In Decimal | Code in binary |
|------|-----------------|----------------|
| A    | 0               | 0              |   
| B    | 1               | 1              |
| C    | 2               | 10             |
| D    | 3               | 11             |
| E    | 4               | 100            |
| F    | 5               | 101            |
| G    | 6               | 110            |
| H    | 7               | 111            |

`H A C -> 111 0 10`

`111010`

`11 10 1 0 -> D C B A`

`Redefined Encoding Table`

| Char | Code In Decimal | Code in binary |
|------|-----------------|----------------|
| A    | 0               | 000            |   
| B    | 1               | 001            |
| C    | 2               | 010            |
| D    | 3               | 011            |
| E    | 4               | 100            |
| F    | 5               | 101            |
| G    | 6               | 110            |
| H    | 7               | 111            |

`H A C -> 111 000 010`

`111000010`

`111 000 010 -> HAC`

This encoding logic is exactly the logic used in the encoding dominant from the mid-1960s to the early 1990s, called ASCII. Of course, the ASCII table consisted of more then just 8 symbols. And 33

## Introducing clever rules. UTF-8

| Leading Byte Range (in binary) | Number of Bytes |
|--------------------------------|-----------------|
| 0xxxxxxx                       | 1               |
| 110xxxxx                       | 2               |
| 1110xxxx                       | 3               |
| 11110xxx                       | 4               |


With UTF-8 we won't use an artificial example, we'll use the real thing. Moreover, we'll go hard-core, here's our sequence to decode:

```
1110001010000010101111110010000001110100011011110010000011110000100111111000110010011001
```

The first, step is easy: Split it to the chunks of 8.

> A sequence of 8 bits is called a byte. And if computers are 'native' in bits, they are at least upper-intermediate in bytes.

```
11100010 10000010 10111111 00100000 01110100 01101111 00100000 11110000 10011111 10001100 10011001
```

The first byte starts with `1110` so we'll put the first 3 bytes in the first box

> The box represents a character or char for brievity

```yaml
char 1: 11100010 10000010 10111111

remaining: 00100000 01110100 01101111 00100000 11110000 10011111 10001100 10011001
```

Next bytes start from `0` so we'll allocate only this byte in the next box

```yaml
char 1: 11100010 10000010 10111111
char 2: 00100000

remaining: 01110100 01101111 00100000 11110000 10011111 10001100 10011001
```

The story repeats three more times and we get:

```yaml
char 1: 11100010 10000010 10111111
char 2: 00100000
char 3: 01110100
char 4: 01101111
char 5: 00100000

remaining: 11110000 10011111 10001100 10011001
```

The next sequence starts with `11110` bytes, which means all the remaining bytes are part of a single-letter

```yaml
char 1: 11100010 10000010 10111111
char 2: 00100000
char 3: 01110100
char 4: 01101111
char 5: 00100000
char 6: 11110000 10011111 10001100 10011001
```

| Number of Bytes | Format                                |
|-----------------|---------------------------------------|
| 1               | 0xxxxxxx                              |
| 2               | 110xxxxx 10xxxxxx                     |
| 3               | 1110xxxx 10xxxxxx 10xxxxxx            |
| 4               | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx   |


So what the format basically means is to throw out everything that is not in the position of `x`. So, this is what we got:

```yaml
char 1: 0010 000010 111111
char 2: 0100000
char 3: 1110100
char 4: 1101111
char 5: 0100000
char 6: 000 011111 001100 011001
```

And the thing we got is the actual UTF-8 character codes. Almost. UTF-8 codes actually represented in the following form `U+{code hex}`. So let's use [the online tool](https://www.binaryhexconverter.com/binary-to-hex-converter) to convert our binaries to hex

> What the hex? you may ask. Pun intended. Well, hex is short for hexadecimal and it basically means representing a number with A meaning 10, B meaning 11, C - 12, D - 13 -, E - 14, and F - 15. Going deep into hex is out of the scope of this article. Fortunately, the online tool above provides a sophisticated explanation of hex so feel free to dive deep into their explanation if you'd like.

```yaml
char 1: 20BF
char 2: 20
char 3: 74
char 4: 6F
char 5: 20
char 5: 1F319
```

Now if we'll [search UTF-8 characters by their hex codes](https://unicodeplus.com/) 

> The actual UTF-8 table is too big to even fit on a single web page.

We'll be able to get that

```yaml
char 1: 20BF -> 'â‚¿'
char 2: 20 -> ' ' (Space)
char 3: 74 -> t
char 4: 6F -> o
char 5: 20 -> ' ' (Space)
char 5: 1F319 -> 'ðŸŒ™'
```

So the sentence we got is: "â‚¿ to ðŸŒ™".

> Yes, emojis are also part of the UTF-8!

## TLDR

# Proposed Structure

- [ ] Introduction
    - [ ] Mention the thesis of a computer talking in 1s and 0s
    - [ ] Propose asking how would we pass a message like "Hello" (pick something illustrative for the padding problem). 
- [ ] Naive Encoding and ASCII
    - [ ] Assign codes to a few letters: create 3-bit encoding
    - [ ] Encode the message (naive way).
    - [ ] Decode the message incorrectly (highlighting the problem).
    - [ ] Propose padding.
    - [ ] Encode and decode correctly
    - [ ] Note that we just created/reproduced ASCII, with notice that it consisted of more characters.
    - [ ] Decode "Hi" using the real ASCII encodings.
- [ ] UTF-8
    - [ ] Highlight that ASCII only included English letters and that this was not enough
    - [ ] Highlight that if we use fixed-size encoding it will probably be too redundant
    - [ ] Explain what UTF did instead
    - [ ] Decode a message from two non-ASCII characters.
    - [ ] Decode an actual message.
- [ ] Recap
    - [ ] Here's how you talk in bytes: You map 7 0s and 1s to our "real" symbols and send chuncks of 7 bits instead of the actual symbols
    - [ ] If you want to get fancy before sending the actual "code" send information about how long the code will be. That What UTF-8 did.
    - [ ] TLDR hex. And tell that explaining "What the hex? (the pun intended)" is out of the scope of this article.
    - [ ] Say that for now you just cover basics "So for the AI takeover you know the basics of computers "language" ðŸ˜„."
